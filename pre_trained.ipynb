{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-30T21:05:58.440831Z","iopub.status.busy":"2023-05-30T21:05:58.440492Z","iopub.status.idle":"2023-05-30T21:06:41.426871Z","shell.execute_reply":"2023-05-30T21:06:41.425533Z","shell.execute_reply.started":"2023-05-30T21:05:58.440801Z"},"id":"Rdxpox811Zjx","trusted":true},"outputs":[],"source":["! pip install transformers datasets\n","! pip install evaluate\n","! pip install sentence-transformers\n","! pip install -U accelerate"]},{"cell_type":"markdown","metadata":{"id":"Cc_H7oqS1Zjz"},"source":["# Μέρος Α: Fine-tune a pretrained model"]},{"cell_type":"markdown","metadata":{"id":"y2UxEv7x1Zj1"},"source":["## Yelp polarity"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-30T21:12:07.310062Z","iopub.status.busy":"2023-05-30T21:12:07.309675Z","iopub.status.idle":"2023-05-30T21:12:32.795373Z","shell.execute_reply":"2023-05-30T21:12:32.793944Z","shell.execute_reply.started":"2023-05-30T21:12:07.310032Z"},"id":"uS3fgJzzNBQL","trusted":true},"outputs":[],"source":["from datasets import load_dataset\n","\n","# insert your code here\n","\n","dataset = load_dataset(\"yelp_polarity\")\n","\n","#dataset[\"train\"][100]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T14:41:45.634622Z","iopub.status.busy":"2023-05-29T14:41:45.633681Z","iopub.status.idle":"2023-05-29T14:41:45.647152Z","shell.execute_reply":"2023-05-29T14:41:45.645889Z","shell.execute_reply.started":"2023-05-29T14:41:45.634575Z"},"trusted":true},"outputs":[],"source":["dataset[\"train\"][0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# insert your code here\n","from datasets import Dataset\n","import numpy as np\n","import pandas as pd\n","samples = 300\n","\n","train_sampled_indices = np.random.choice(np.arange(0, len(dataset[\"train\"]) - 1), samples, replace=False)\n","test_sampled_indices = np.random.choice(np.arange(0, len(dataset[\"test\"]) - 1), samples, replace=False)\n","                                   \n","train_dataset = [dataset[\"train\"][int(i)] for i in train_sampled_indices]\n","test_dataset = [dataset[\"test\"][int(i)] for i in test_sampled_indices]\n","\n","train_dataset = Dataset.from_pandas(pd.DataFrame(train_dataset))\n","test_dataset = Dataset.from_pandas(pd.DataFrame(test_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:34:06.372060Z","iopub.status.busy":"2023-05-29T12:34:06.371351Z","iopub.status.idle":"2023-05-29T12:34:06.605505Z","shell.execute_reply":"2023-05-29T12:34:06.604602Z","shell.execute_reply.started":"2023-05-29T12:34:06.372024Z"},"trusted":true},"outputs":[],"source":["train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(300))\n","eval_dataset = dataset[\"test\"].shuffle(seed=42).select(range(300))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:10:39.880912Z","iopub.status.busy":"2023-05-29T12:10:39.880043Z","iopub.status.idle":"2023-05-29T12:10:39.888245Z","shell.execute_reply":"2023-05-29T12:10:39.887321Z","shell.execute_reply.started":"2023-05-29T12:10:39.880866Z"},"id":"R-Kj4N9yMaoD","trusted":true},"outputs":[],"source":["train_dataset"]},{"cell_type":"markdown","metadata":{"id":"3N0xadZjXiIF"},"source":["#  LLMs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:49:44.186676Z","iopub.status.busy":"2023-05-29T12:49:44.186275Z","iopub.status.idle":"2023-05-29T12:49:45.745814Z","shell.execute_reply":"2023-05-29T12:49:45.744784Z","shell.execute_reply.started":"2023-05-29T12:49:44.186643Z"},"id":"_lnywJkqyL64","trusted":true},"outputs":[],"source":["# insert your code here\n","\n","from transformers import AutoTokenizer, RobertaForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n","model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:49:53.804420Z","iopub.status.busy":"2023-05-29T12:49:53.804004Z","iopub.status.idle":"2023-05-29T12:49:53.818110Z","shell.execute_reply":"2023-05-29T12:49:53.816307Z","shell.execute_reply.started":"2023-05-29T12:49:53.804377Z"},"id":"-1AkZ0rLPq2d","trusted":true},"outputs":[],"source":["def tokenize_function(examples):\n","    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n","\n","# insert your code here\n","train_dataset = train_dataset.map(tokenize_function, batched=True)\n","eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:12:26.144282Z","iopub.status.busy":"2023-05-29T12:12:26.143593Z","iopub.status.idle":"2023-05-29T12:12:26.150577Z","shell.execute_reply":"2023-05-29T12:12:26.149386Z","shell.execute_reply.started":"2023-05-29T12:12:26.144248Z"},"id":"IWFzP_7SQVOm","trusted":true},"outputs":[],"source":["train_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:24:12.493672Z","iopub.status.busy":"2023-05-29T12:24:12.493239Z","iopub.status.idle":"2023-05-29T12:24:23.229234Z","shell.execute_reply":"2023-05-29T12:24:23.227929Z","shell.execute_reply.started":"2023-05-29T12:24:12.493632Z"},"trusted":true},"outputs":[],"source":["pip install -U accelerate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:49:59.204700Z","iopub.status.busy":"2023-05-29T12:49:59.203566Z","iopub.status.idle":"2023-05-29T12:49:59.683518Z","shell.execute_reply":"2023-05-29T12:49:59.682461Z","shell.execute_reply.started":"2023-05-29T12:49:59.204410Z"},"id":"0MPHrmRL1Zj7","trusted":true},"outputs":[],"source":["import numpy as np\n","import evaluate\n","import torch\n","from tqdm import tqdm\n","import accelerate #import PartialState \n","from transformers import pipeline\n","\n","metric = evaluate.load(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:50:05.157635Z","iopub.status.busy":"2023-05-29T12:50:05.157227Z","iopub.status.idle":"2023-05-29T12:50:05.198828Z","shell.execute_reply":"2023-05-29T12:50:05.195916Z","shell.execute_reply.started":"2023-05-29T12:50:05.157602Z"},"id":"Ga0fADv91Zj7","trusted":true},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","from transformers import get_constant_schedule\n","\n","epochs = 10\n","\n","args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", per_device_train_batch_size=8, num_train_epochs = epochs)\n","\n","\n","# insert your code here\n","# optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-5)\n","\n","# scheduler\n","scheduler = get_constant_schedule(optimizer)\n","# etc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:50:09.419479Z","iopub.status.busy":"2023-05-29T12:50:09.419098Z","iopub.status.idle":"2023-05-29T12:50:09.562419Z","shell.execute_reply":"2023-05-29T12:50:09.561313Z","shell.execute_reply.started":"2023-05-29T12:50:09.419428Z"},"id":"nHWYlDW21Zj8","trusted":true},"outputs":[],"source":["trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n","    optimizers = (optimizer, scheduler)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:39:16.096234Z","iopub.status.busy":"2023-05-29T12:39:16.095867Z","iopub.status.idle":"2023-05-29T12:42:47.691117Z","shell.execute_reply":"2023-05-29T12:42:47.688503Z","shell.execute_reply.started":"2023-05-29T12:39:16.096205Z"},"id":"PvY7bzp01Zj8","trusted":true},"outputs":[],"source":["#lr = 1e-4 - epochs = 10  - bsize = 16\n","trained_model=trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:44:51.693998Z","iopub.status.busy":"2023-05-29T12:44:51.693284Z","iopub.status.idle":"2023-05-29T12:48:23.640558Z","shell.execute_reply":"2023-05-29T12:48:23.639530Z","shell.execute_reply.started":"2023-05-29T12:44:51.693959Z"},"trusted":true},"outputs":[],"source":["#lr = 1e-5 - epochs = 10  - bsize = 16\n","trained_model=trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T12:50:13.901478Z","iopub.status.busy":"2023-05-29T12:50:13.900751Z","iopub.status.idle":"2023-05-29T12:53:50.672361Z","shell.execute_reply":"2023-05-29T12:53:50.671268Z","shell.execute_reply.started":"2023-05-29T12:50:13.901423Z"},"trusted":true},"outputs":[],"source":["#lr = 1e-5 - epochs = 10  - bsize = 8\n","trained_model=trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"0eR7gCPovmFN"},"source":["# Transfer Learning"]},{"cell_type":"markdown","metadata":{"id":"vy3VluE4i3e6"},"source":["## B1. Piqa dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T15:01:36.585034Z","iopub.status.busy":"2023-05-29T15:01:36.584439Z","iopub.status.idle":"2023-05-29T15:01:37.322320Z","shell.execute_reply":"2023-05-29T15:01:37.319282Z","shell.execute_reply.started":"2023-05-29T15:01:36.585002Z"},"id":"v4eyhC27i8bH","trusted":true},"outputs":[],"source":["# # insert your code here (load dataset)\n","\n","dataset = load_dataset(\"piqa\")\n","eval_dataset = dataset[\"train\"].shuffle(seed=42).select(range(100))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T14:14:24.866654Z","iopub.status.busy":"2023-05-29T14:14:24.865529Z","iopub.status.idle":"2023-05-29T14:14:42.835819Z","shell.execute_reply":"2023-05-29T14:14:42.834755Z","shell.execute_reply.started":"2023-05-29T14:14:24.866609Z"},"id":"a6lSPO6NMekO","trusted":true},"outputs":[],"source":["# insert your code here (models)\n","\n","from transformers import AutoTokenizer, AutoModelForMultipleChoice\n","\n","tokenizer_roberta = AutoTokenizer.from_pretrained(\"roberta-base\")\n","model_roberta = AutoModelForMultipleChoice.from_pretrained(\"roberta-base\")\n","\n","tokenizer_yoso = AutoTokenizer.from_pretrained(\"uw-madison/yoso-4096\")\n","model_yoso = AutoModelForMultipleChoice.from_pretrained(\"uw-madison/yoso-4096\")\n","\n","tokenizer_mega = AutoTokenizer.from_pretrained(\"mnaylor/mega-base-wikitext\")\n","model_mega = AutoModelForMultipleChoice.from_pretrained(\"mnaylor/mega-base-wikitext\")\n","\n","tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","model_bert = AutoModelForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n","\n","tokenizer_electra = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n","model_electra = AutoModelForMultipleChoice.from_pretrained(\"google/electra-small-discriminator\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T14:09:44.851853Z","iopub.status.busy":"2023-05-29T14:09:44.851353Z","iopub.status.idle":"2023-05-29T14:09:44.865034Z","shell.execute_reply":"2023-05-29T14:09:44.863249Z","shell.execute_reply.started":"2023-05-29T14:09:44.851812Z"},"id":"OG2CkRVCOHtE","trusted":true},"outputs":[],"source":["# insert your code here (function for ending prediction)\n","def ending_prediction(dataset, model, tokenizer):\n","    pred = []\n","    true = []\n","    for d in dataset:\n","        prompt = d[\"goal\"]\n","        candidate1 = d[\"sol1\"]\n","        candidate2 = d[\"sol2\"]\n","        labels = d[\"label\"]\n","        if tokenizer.pad_token is None:\n","            tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","        inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=\"pt\", padding=True, truncation=True)\n","        labels = torch.tensor(labels).unsqueeze(0)\n","        outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n","        logits = outputs.logits\n","        predicted_class = logits.argmax().item()\n","        true.append(d[\"label\"])\n","        pred.append(predicted_class)\n","    \n","    print(metric.compute(predictions=pred, references=true))\n","\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T14:15:12.401431Z","iopub.status.busy":"2023-05-29T14:15:12.400320Z","iopub.status.idle":"2023-05-29T14:16:11.925149Z","shell.execute_reply":"2023-05-29T14:16:11.923895Z","shell.execute_reply.started":"2023-05-29T14:15:12.401385Z"},"trusted":true},"outputs":[],"source":["print(\"YOSO: \")\n","ending_prediction(eval_dataset, model_yoso, tokenizer_yoso)\n","print(\"Roberta: \")\n","ending_prediction(eval_dataset, model_roberta, tokenizer_roberta)\n","print(\"Mega: \")\n","ending_prediction(eval_dataset, model_mega, tokenizer_mega)\n","print(\"BERT: \")\n","ending_prediction(eval_dataset, model_bert, tokenizer_bert)\n","print(\"Electra: \")\n","ending_prediction(eval_dataset, model_electra, tokenizer_electra)"]},{"cell_type":"markdown","metadata":{"id":"Tz8-kVRS1w2q"},"source":["## B2. Truthful QA"]},{"cell_type":"markdown","metadata":{"id":"d59haHDaA3X0"},"source":["### Sentence Transformers\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T14:03:34.564676Z","iopub.status.busy":"2023-05-29T14:03:34.564224Z","iopub.status.idle":"2023-05-29T14:03:34.572544Z","shell.execute_reply":"2023-05-29T14:03:34.571460Z","shell.execute_reply.started":"2023-05-29T14:03:34.564644Z"},"id":"rdaiwnFx_ipu","trusted":true},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_similarity\n","def get_cosine_similarity(feature_vec_1, feature_vec_2):    \n","    return cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T14:03:51.944064Z","iopub.status.busy":"2023-05-29T14:03:51.943349Z","iopub.status.idle":"2023-05-29T14:03:58.682426Z","shell.execute_reply":"2023-05-29T14:03:58.681387Z","shell.execute_reply.started":"2023-05-29T14:03:51.944030Z"},"id":"UGhq0UGF-bW0","trusted":true},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n","\n","model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n","embeddings = model.encode(sentences)\n","\n","get_cosine_similarity(embeddings[0], embeddings[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-29T14:29:32.898874Z","iopub.status.busy":"2023-05-29T14:29:32.898417Z","iopub.status.idle":"2023-05-29T14:29:34.308878Z","shell.execute_reply":"2023-05-29T14:29:34.305867Z","shell.execute_reply.started":"2023-05-29T14:29:32.898831Z"},"id":"B3aXIPmDIA7F","trusted":true},"outputs":[],"source":["# insert your code here (load dataset)\n","dataset = load_dataset(\"truthful_qa\", 'generation')\n","#eval_dataset = dataset[\"train\"].shuffle(seed=42).select(range(100))\n","\n","eval_dataset[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZSQmLMDIJ3A"},"outputs":[],"source":["# insert your code here (load models for semantic similarity and QA)\n","model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCNrR5nV18_G"},"outputs":[],"source":["# insert your code here (function for optimal correct answers & semantic similarity)"]},{"cell_type":"markdown","metadata":{"id":"jQATbpGyeByP"},"source":["## Β3. Winogrande dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-30T21:12:32.798118Z","iopub.status.busy":"2023-05-30T21:12:32.797685Z","iopub.status.idle":"2023-05-30T21:12:34.010956Z","shell.execute_reply":"2023-05-30T21:12:34.009093Z","shell.execute_reply.started":"2023-05-30T21:12:32.798082Z"},"id":"s-Jkr97igAJO","trusted":true},"outputs":[],"source":["# insert your code here (load dataset)\n","from datasets import Dataset\n","import numpy as np\n","dataset = load_dataset(\"winogrande\", 'winogrande_xs')\n","eval_dataset = dataset[\"train\"].shuffle(seed=42).select(range(100))"]},{"cell_type":"markdown","metadata":{},"source":["**Text Classification**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-30T21:13:02.147456Z","iopub.status.busy":"2023-05-30T21:13:02.147102Z","iopub.status.idle":"2023-05-30T21:13:55.416600Z","shell.execute_reply":"2023-05-30T21:13:55.415919Z","shell.execute_reply.started":"2023-05-30T21:13:02.147431Z"},"id":"m1oZcCm2c29U","trusted":true},"outputs":[],"source":["# insert your code here (load models)\n","from transformers import pipeline\n","classifier_bert = pipeline(\"text-classification\", model=\"bert-base-uncased\")\n","classifier_pavlov = pipeline(\"text-classification\", model=\"DeepPavlov/roberta-large-winogrande\") \n","classifier_roberta = pipeline(\"text-classification\", model=\"roberta-base\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-30T21:35:37.482607Z","iopub.status.busy":"2023-05-30T21:35:37.482178Z","iopub.status.idle":"2023-05-30T21:35:46.062394Z","shell.execute_reply":"2023-05-30T21:35:46.061136Z","shell.execute_reply.started":"2023-05-30T21:35:37.482573Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n","label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n","tokenizer_pavlov = AutoTokenizer.from_pretrained(\"DeepPavlov/roberta-large-winogrande\")\n","model_pavlov = AutoModelForSequenceClassification.from_pretrained(\"DeepPavlov/roberta-large-winogrande\")\n","tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","model_bert = AutoModelForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",")\n","\n","model_distilbert = AutoModelForSequenceClassification.from_pretrained(\n","    \"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id\n",")\n","tokenizer_distilbert = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-30T21:22:20.878927Z","iopub.status.busy":"2023-05-30T21:22:20.878501Z","iopub.status.idle":"2023-05-30T21:22:20.889106Z","shell.execute_reply":"2023-05-30T21:22:20.887045Z","shell.execute_reply.started":"2023-05-30T21:22:20.878886Z"},"id":"9m6akMdBuFcw","trusted":true},"outputs":[],"source":["# insert your code here (create pipelines)\n","import torch\n","            \n","def fill(dataset, classifier):\n","    acc = 0\n","    for d in dataset:\n","        ans = d[\"answer\"]\n","        sentence = d[\"sentence\"]\n","        result = sentence.split(\"_\")\n","        input1 = result[0] + d[\"option1\"] + result[1]\n","        input2 = result[0] + d[\"option2\"] + result[1]\n","        out1 = classifier(input1)\n","        out2 = classifier(input2)\n","        print(out2[0][\"label\"])\n","        if(int(ans) == 2 and out1[0][\"label\"] == 'LABEL_0' and out2[0][\"label\"] == 'LABEL_1'): acc += 1\n","        if(int(ans) == 1 and out1[0][\"label\"] == 'LABEL_1' and out2[0][\"label\"] == 'LABEL_0'): acc += 1\n","\n","    print(acc/100)"]},{"cell_type":"markdown","metadata":{},"source":["**Multiple Choice**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-30T21:44:15.102423Z","iopub.status.busy":"2023-05-30T21:44:15.101975Z","iopub.status.idle":"2023-05-30T21:44:17.013311Z","shell.execute_reply":"2023-05-30T21:44:17.011000Z","shell.execute_reply.started":"2023-05-30T21:44:15.102392Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForMultipleChoice\n","import evaluate\n","metric = evaluate.load(\"accuracy\")\n","tokenizer_roberta = AutoTokenizer.from_pretrained(\"roberta-base\")\n","model_roberta = AutoModelForMultipleChoice.from_pretrained(\"roberta-base\")\n","\n","tokenizer_mega = AutoTokenizer.from_pretrained(\"mnaylor/mega-base-wikitext\")\n","model_mega = AutoModelForMultipleChoice.from_pretrained(\"mnaylor/mega-base-wikitext\")\n","\n","tokenizer_bert = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","model_bert = AutoModelForMultipleChoice.from_pretrained(\"bert-base-uncased\")\n","\n","def fill(dataset, model, tokenizer):\n","    pred = []\n","    true = []\n","    for d in dataset:\n","        sentence = d[\"sentence\"]\n","        result = sentence.split(\"_\")\n","        prompt = result[0]\n","        candidate1 = d[\"option1\"] + result[1]\n","        candidate2 = d[\"option2\"] + result[1]\n","        ans = int(d[\"answer\"]) - 1\n","        labels = ans\n","        if tokenizer.pad_token is None:\n","            tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","        inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=\"pt\", padding=True, truncation=True)\n","        labels = torch.tensor(labels).unsqueeze(0)\n","        outputs = model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels=labels)\n","        logits = outputs.logits\n","        predicted_class = logits.argmax().item()\n","        true.append(ans)\n","        pred.append(predicted_class)\n","    \n","    print(metric.compute(predictions=pred, references=true))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-30T21:44:19.688140Z","iopub.status.busy":"2023-05-30T21:44:19.687690Z","iopub.status.idle":"2023-05-30T21:44:33.999507Z","shell.execute_reply":"2023-05-30T21:44:33.998056Z","shell.execute_reply.started":"2023-05-30T21:44:19.688107Z"},"id":"PR6sz6xug_7N","trusted":true},"outputs":[],"source":["# insert your code here (function for predicting best fill)\n","print(\"Roberta:\")\n","fill(eval_dataset, model_roberta, tokenizer_roberta)\n","print(\"Bert:\")\n","fill(eval_dataset, model_bert, tokenizer_bert)\n","print(\"Mega:\")\n","fill(eval_dataset, model_mega, tokenizer_mega)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
